---
title: "Smooth and thin data"
author: "Johannes Krietsch"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Smooth and thin data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  out.width = "100%",
  fig.width = 8.89, fig.height = 5,
  dpi = 300,
  dev = "ragg_png"
)
```

 This vignette shows how to smooth and thin WATLAS data. 

```{r}
# Packages
library(tools4watlas)
library(data.table)
library(ggplot2)

# Path to csv with raw data
data_path <- system.file(
  "extdata", "watlas_data_filtered.csv",
  package = "tools4watlas"
)

# Load data
data <- fread(data_path, yaml = TRUE)

```


## Median smooth data

To further reduce error in the localization data, a basic smoother such as a median filter can be applied. The resulting table has the smoothed location stored in the `x` and `y` column and the original location stored in the `x_raw` and `y_raw` column. 

```{r echo=T, results='hide'}		

# split in list as atl_median_smooth() does not work by tag
data_list <- split(data, by = "tag")

# Smooth the data
med_filter <- 5 # number of localizations within window for smoothing

# since the function modifies in place, we shall make a copy
data_smooth <- copy(data_list)

lapply(
  X = data_smooth,
  FUN = atl_median_smooth,
  moving_window = med_filter
) |> invisible()
```

### Recalculate speed

After smoothing the data, the speeds need to be recalculated. We now also calculate turning angles. 
Note: the distance between smoothed positions can be 0 and therefore will produce NAs and a warning

```{r echo=T}		
# Recalculate speed
lapply(data_list, atl_get_speed) |> invisible()
```

#### Look at the data

This plot just shows one example.

```{r, fig.cap = "Smoothed track (black) on top of raw track (red)"}	
# select data from first list
d1_raw <- data_list[[1]]
d1_smooth <- data_smooth[[1]]

# subset some data to look at
from <- min(d1_raw[, datetime]) + 1 * 3600
to <- min(d1_raw[, datetime]) + 12 * 3600

d1_raw <- d1_raw[datetime %between% c(from, to)]
d1_smooth <- d1_smooth[datetime %between% c(from, to)]

# Create basemap
bm <- atl_create_bm(d1_smooth)

# Plot
bm +
  geom_path(data = d1_raw, aes(x, y), color = "firebrick3", linewidth = 0.5) +
  geom_path(data = d1_smooth, aes(x, y), color = "black", linewidth = 0.5) +
  geom_point(data = d1_raw, aes(x, y), color = "firebrick3", size = 1.2) +
  geom_point(data = d1_smooth, aes(x, y), color = "black", size = 1)
```


## Thin data

Depending on the desired analysis, it might make sense to thin data, either by aggregation or by subsampling. Both methods return fixed time steps (depending on the interval). 

### By aggregation

Returns the average of all columns for each time step. The additional column `n_aggregated` shows how many locations were aggregated for this location. Time and datetime are returned rounded to the interval.

```{r echo=T}		
# rbind data
data <- rbindlist(data_smooth)

# Thin the data by aggregation with a 60-second interval
thinned_aggregated <- atl_thin_data(
  data = data,
  interval = 60,
  id_columns = "tag",
  method = "aggregate"
)

# Show head of selected data
head(thinned_aggregated[, .(tag, time, datetime, x, y, n_aggregated)]) |>
  knitr::kable(digits = 2)
```

### By subsampling

Returns one random location for each time step. The additional column `n_subsampled` shows from how many locations this location was sampled.

```{r echo=T}		
# Thin the data by subsampling with a 60-second interval
thinned_subsampled <- atl_thin_data(
  data = data,
  interval = 60,
  id_columns = "tag",
  method = "subsample"
)

# Show head of selected data
head(thinned_subsampled[, .(tag, time, datetime, x, y, n_subsampled)]) |>
  knitr::kable(digits = 2)
```


## Save data

```{r, eval = FALSE}
# Save data
fwrite(thinned_aggregated,
  file = "../inst/extdata/watlas_data_aggregated.csv", yaml = TRUE
)
```

